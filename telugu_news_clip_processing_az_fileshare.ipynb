{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aithentic-dev/newspaper-clip-extraction/blob/main/telugu_news_clip_processing_az_fileshare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "id": "e00d1e9f",
      "cell_type": "markdown",
      "source": [
        "# Telugu News Clip Processing with Gemini + Azure File Share\n",
        "This Colab notebook processes Telugu newspaper clips from an **Azure File Share**. It classifies images as news or non-news, extracts clean Telugu text using Google Gemini, and stores results back into the file share.\n",
        "\n",
        "- Source: `raw/source`\n",
        "- Success: `raw/success`\n",
        "- Fail: `raw/fail`\n",
        "\n",
        "Only files in the root of `source/` are processed (child directories are skipped)."
      ],
      "metadata": {
        "id": "e00d1e9f"
      }
    },
    {
      "id": "30345f07",
      "cell_type": "code",
      "metadata": {
        "id": "30345f07"
      },
      "execution_count": null,
      "source": [
        "# --- Step 1. Install SDKs ---\n",
        "!pip install -q azure-storage-file-share google-generativeai\n",
        "\n",
        "import os\n",
        "import json\n",
        "import google.generativeai as genai\n",
        "import PIL.Image\n",
        "from io import BytesIO\n",
        "from azure.storage.fileshare import ShareServiceClient\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "# --- Configure Gemini API ---\n",
        "#os.environ[\"GOOGLE_API_KEY\"] = \"api key here\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "model = genai.GenerativeModel(\"gemini-2.0-flash-001\")\n",
        "#model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "# --- Configure Azure File Share ---\n",
        "AZURE_CONNECTION_STRING = userdata.get(\"AZURE_CONNECTION_STRING\")\n",
        "FILE_SHARE_NAME = \"lqr\"\n",
        "\n",
        "service_client = ShareServiceClient.from_connection_string(AZURE_CONNECTION_STRING)\n",
        "share_client = service_client.get_share_client(FILE_SHARE_NAME)\n",
        "\n",
        "# Directories inside the file share\n",
        "SOURCE_DIR = \"source\"\n",
        "SUCCESS_DIR = \"success\"\n",
        "FAIL_DIR = \"fail\"\n"
      ],
      "outputs": []
    },
    {
      "id": "5f10cdc0",
      "cell_type": "code",
      "metadata": {
        "id": "5f10cdc0"
      },
      "execution_count": null,
      "source": [
        "def classify_image_bytes(image_bytes: bytes) -> str:\n",
        "    \"\"\"Classify image as News Article / Advertisement / Meme / Other.\"\"\"\n",
        "    img = PIL.Image.open(BytesIO(image_bytes))\n",
        "\n",
        "    prompt = \"\"\"\n",
        "    Classify this image into one of these categories:\n",
        "    1. News Article (contains Telugu news text with a headline and body)\n",
        "    2. Advertisement (commercial ads, posters, offers)\n",
        "    3. Meme / Cartoon (jokes, funny posts, non-news)\n",
        "    4. Other\n",
        "\n",
        "    Return only the category name.\n",
        "    \"\"\"\n",
        "    response = model.generate_content([prompt, img])\n",
        "    return response.text.strip()\n"
      ],
      "outputs": []
    },
    {
      "id": "775a1390",
      "cell_type": "code",
      "metadata": {
        "id": "775a1390"
      },
      "execution_count": null,
      "source": [
        "def extract_telugu_text_bytes(image_bytes: bytes) -> dict:\n",
        "    \"\"\"Extract Telugu text from news article image and return as JSON.\"\"\"\n",
        "    img = PIL.Image.open(BytesIO(image_bytes))\n",
        "\n",
        "    prompt = \"\"\"\n",
        "    You are given a Telugu newspaper clipping image.\n",
        "    - Extract the Telugu text clearly.\n",
        "    - Correct OCR mistakes and remove noise.\n",
        "    - Keep context and meaning intact.\n",
        "    - Maintain Telugu script (do not translate).\n",
        "    Return JSON format:\n",
        "    {\n",
        "      \"headline\": \"...\",\n",
        "      \"content\": \"...\"\n",
        "    }\n",
        "    \"\"\"\n",
        "    response = model.generate_content([prompt, img])\n",
        "\n",
        "    try:\n",
        "        return json.loads(response.text)\n",
        "    except:\n",
        "        return {\"headline\": \"\", \"content\": response.text.strip()}\n"
      ],
      "outputs": []
    },
    {
      "id": "b26862ba",
      "cell_type": "code",
      "metadata": {
        "id": "b26862ba"
      },
      "execution_count": null,
      "source": [
        "def process_files_in_root():\n",
        "    \"\"\"\n",
        "    Process only JPG/PNG files directly in the root of the file share.\n",
        "    News ‚Üí save to 'success' dir with JSON.\n",
        "    Non-news ‚Üí copy to 'fail' dir.\n",
        "    \"\"\"\n",
        "    items = share_client.list_directories_and_files()\n",
        "\n",
        "    for item in items:\n",
        "        if item['is_directory']:\n",
        "            continue  # skip subdirectories (fail/, success/, etc.)\n",
        "        if not item['name'].lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "            continue\n",
        "\n",
        "        print(f\"Processing: {item['name']}\")\n",
        "        file_client = share_client.get_file_client(item['name'])\n",
        "        downloader = file_client.download_file()\n",
        "        image_bytes = downloader.readall()\n",
        "\n",
        "        # Step 1: Classify\n",
        "        category = classify_image_bytes(image_bytes)\n",
        "        print(f\"  Category: {category}\")\n",
        "\n",
        "        if category == \"News Article\":\n",
        "            extracted = extract_telugu_text_bytes(image_bytes)\n",
        "\n",
        "            # Save original image to success\n",
        "            success_dir_client = share_client.get_directory_client(SUCCESS_DIR)\n",
        "            success_file = success_dir_client.get_file_client(item['name'])\n",
        "            try:\n",
        "                success_file.delete_file()\n",
        "            except Exception:\n",
        "                pass\n",
        "            success_file.upload_file(image_bytes)\n",
        "\n",
        "            # Save extracted JSON\n",
        "            json_name = item['name'].rsplit(\".\", 1)[0] + \".json\"\n",
        "            json_file = success_dir_client.get_file_client(json_name)\n",
        "            try:\n",
        "                json_file.delete_file()\n",
        "            except Exception:\n",
        "                pass\n",
        "            json_file.upload_file(json.dumps(extracted, ensure_ascii=False, indent=2))\n",
        "\n",
        "            print(f\"  ‚úÖ Saved {item['name']} and {json_name} to {SUCCESS_DIR}\")\n",
        "        else:\n",
        "            # Save image to fail\n",
        "            fail_dir_client = share_client.get_directory_client(FAIL_DIR)\n",
        "            fail_file = fail_dir_client.get_file_client(item['name'])\n",
        "            try:\n",
        "                fail_file.delete_file()\n",
        "            except Exception:\n",
        "                pass\n",
        "            fail_file.upload_file(image_bytes)\n",
        "            print(f\"  ‚è≠Ô∏è Skipped, moved {item['name']} to {FAIL_DIR}\")\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **This will extract source folder information into json file metatdata when processed**"
      ],
      "metadata": {
        "id": "FRZnVPESgXEa"
      },
      "id": "FRZnVPESgXEa"
    },
    {
      "cell_type": "code",
      "source": [
        "def process_all_sources():\n",
        "    \"\"\"\n",
        "    Process all JPG/PNG files inside each subfolder of SOURCE_DIR (e.g., Eenadu, Sakshi).\n",
        "    News ‚Üí save to 'success/{source}/' with JSON (including metadata).\n",
        "    Non-news ‚Üí save to 'fail/{source}/'.\n",
        "    \"\"\"\n",
        "\n",
        "    source_root = share_client.get_directory_client(SOURCE_DIR)\n",
        "    sources = source_root.list_directories_and_files()\n",
        "\n",
        "    for src in sources:\n",
        "        if not src['is_directory']:\n",
        "            continue\n",
        "\n",
        "        source_name = src['name']  # e.g., Eenadu, Sakshi\n",
        "        print(f\"üìÇ Processing source folder: {source_name}\")\n",
        "\n",
        "        src_dir = source_root.get_subdirectory_client(source_name)\n",
        "        files = src_dir.list_directories_and_files()\n",
        "\n",
        "        for f in files:\n",
        "            if f['is_directory']:\n",
        "                continue\n",
        "            if not f['name'].lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "                continue\n",
        "\n",
        "            print(f\"  üñºÔ∏è Processing: {f['name']}\")\n",
        "            file_client = src_dir.get_file_client(f['name'])\n",
        "            downloader = file_client.download_file()\n",
        "            image_bytes = downloader.readall()\n",
        "\n",
        "            # Step 1: Classify\n",
        "            category = classify_image_bytes(image_bytes)\n",
        "            print(f\"    Category: {category}\")\n",
        "\n",
        "            if category == \"News Article\":\n",
        "                extracted = extract_telugu_text_bytes(image_bytes)\n",
        "                extracted[\"source\"] = source_name  # ‚úÖ add source metadata\n",
        "\n",
        "                # Ensure success/{source}/ exists\n",
        "                success_root = share_client.get_directory_client(SUCCESS_DIR)\n",
        "                try:\n",
        "                    success_root.create_directory()\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "                success_dir = share_client.get_directory_client(f\"{SUCCESS_DIR}/{source_name}\")\n",
        "                try:\n",
        "                    success_dir.create_directory()\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "                # Save image\n",
        "                success_file = success_dir.get_file_client(f['name'])\n",
        "                try:\n",
        "                    success_file.delete_file()\n",
        "                except Exception:\n",
        "                    pass\n",
        "                success_file.upload_file(image_bytes)\n",
        "\n",
        "                # Save JSON\n",
        "                json_name = f['name'].rsplit(\".\", 1)[0] + \".json\"\n",
        "                json_file = success_dir.get_file_client(json_name)\n",
        "                try:\n",
        "                    json_file.delete_file()\n",
        "                except Exception:\n",
        "                    pass\n",
        "                json_file.upload_file(json.dumps(extracted, ensure_ascii=False, indent=2))\n",
        "\n",
        "                print(f\"    ‚úÖ Saved {f['name']} and {json_name} to success/{source_name}\")\n",
        "            else:\n",
        "                # Ensure fail/{source}/ exists\n",
        "                fail_root = share_client.get_directory_client(FAIL_DIR)\n",
        "                try:\n",
        "                    fail_root.create_directory()\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "                fail_dir = share_client.get_directory_client(f\"{FAIL_DIR}/{source_name}\")\n",
        "                try:\n",
        "                    fail_dir.create_directory()\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "                fail_file = fail_dir.get_file_client(f['name'])\n",
        "                try:\n",
        "                    fail_file.delete_file()\n",
        "                except Exception:\n",
        "                    pass\n",
        "                fail_file.upload_file(image_bytes)\n",
        "\n",
        "                print(f\"    ‚è≠Ô∏è Skipped, moved {f['name']} to fail/{source_name}\")\n"
      ],
      "metadata": {
        "id": "XNUe3c-tgWiy"
      },
      "id": "XNUe3c-tgWiy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Added ability to log and verify before process every file to skip if the file already processed.**"
      ],
      "metadata": {
        "id": "jw5jFLsSUDsh"
      },
      "id": "jw5jFLsSUDsh"
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def process_all_sources():\n",
        "    \"\"\"\n",
        "    Process all JPG/PNG files inside each subfolder of SOURCE_DIR (e.g., Eenadu, Sakshi).\n",
        "    News ‚Üí save to 'success/{source}/' with JSON (including metadata).\n",
        "    Non-news ‚Üí save to 'fail/{source}/'.\n",
        "    Maintains a processed.log file in success/ to avoid reprocessing same files.\n",
        "    After processing or skipping, removes the original from source/.\n",
        "    Each log entry includes date, source, filename, and status.\n",
        "    \"\"\"\n",
        "\n",
        "    source_root = share_client.get_directory_client(SOURCE_DIR)\n",
        "    sources = source_root.list_directories_and_files()\n",
        "\n",
        "    # --- Load processed log ---\n",
        "    processed_log_name = \"processed.log\"\n",
        "    processed_records = []\n",
        "    processed_lookup = set()\n",
        "\n",
        "    success_root = share_client.get_directory_client(SUCCESS_DIR)\n",
        "    try:\n",
        "        log_file_client = success_root.get_file_client(processed_log_name)\n",
        "        log_data = log_file_client.download_file().readall().decode(\"utf-8\")\n",
        "        for line in log_data.splitlines():\n",
        "            parts = line.split(\" | \")\n",
        "            if len(parts) >= 3:\n",
        "                _, source, fname, *_ = parts\n",
        "                processed_lookup.add(fname.strip())\n",
        "            processed_records.append(line)\n",
        "    except Exception:\n",
        "        processed_records = []\n",
        "        processed_lookup = set()\n",
        "\n",
        "    for src in sources:\n",
        "        if not src['is_directory']:\n",
        "            continue\n",
        "\n",
        "        source_name = src['name']  # e.g., Eenadu\n",
        "        print(f\"üìÇ Processing source folder: {source_name}\")\n",
        "\n",
        "        src_dir = source_root.get_subdirectory_client(source_name)\n",
        "        files = src_dir.list_directories_and_files()\n",
        "\n",
        "        for f in files:\n",
        "            if f['is_directory']:\n",
        "                continue\n",
        "            if not f['name'].lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "                continue\n",
        "\n",
        "            filename = f['name']\n",
        "            file_client = src_dir.get_file_client(filename)\n",
        "\n",
        "            # Skip if already processed\n",
        "            if filename in processed_lookup:\n",
        "                print(f\"  ‚è≠Ô∏è Skipping {filename} (already processed)\")\n",
        "                try:\n",
        "                    file_client.delete_file()\n",
        "                    print(f\"    üóëÔ∏è Removed duplicate {filename} from source/{source_name}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"    ‚ö†Ô∏è Could not delete duplicate: {e}\")\n",
        "                continue\n",
        "\n",
        "            print(f\"  üñºÔ∏è Processing: {filename}\")\n",
        "            downloader = file_client.download_file()\n",
        "            image_bytes = downloader.readall()\n",
        "\n",
        "            # Step 1: Classify\n",
        "            category = classify_image_bytes(image_bytes)\n",
        "            print(f\"    Category: {category}\")\n",
        "\n",
        "            status = \"success\" if category == \"News Article\" else \"fail\"\n",
        "            today = datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "            if category == \"News Article\":\n",
        "                extracted = extract_telugu_text_bytes(image_bytes)\n",
        "                extracted[\"source\"] = source_name\n",
        "\n",
        "                # Ensure success/{source}/ exists\n",
        "                success_dir = share_client.get_directory_client(f\"{SUCCESS_DIR}/{source_name}\")\n",
        "                try:\n",
        "                    share_client.get_directory_client(SUCCESS_DIR).create_directory()\n",
        "                except Exception:\n",
        "                    pass\n",
        "                try:\n",
        "                    success_dir.create_directory()\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "                # Save image\n",
        "                success_file = success_dir.get_file_client(filename)\n",
        "                try:\n",
        "                    success_file.delete_file()\n",
        "                except Exception:\n",
        "                    pass\n",
        "                success_file.upload_file(image_bytes)\n",
        "\n",
        "                # Save JSON\n",
        "                json_name = filename.rsplit(\".\", 1)[0] + \".json\"\n",
        "                json_file = success_dir.get_file_client(json_name)\n",
        "                try:\n",
        "                    json_file.delete_file()\n",
        "                except Exception:\n",
        "                    pass\n",
        "                json_file.upload_file(json.dumps(extracted, ensure_ascii=False, indent=2))\n",
        "\n",
        "                print(f\"    ‚úÖ Saved {filename} and {json_name} to success/{source_name}\")\n",
        "            else:\n",
        "                # Ensure fail/{source}/ exists\n",
        "                fail_dir = share_client.get_directory_client(f\"{FAIL_DIR}/{source_name}\")\n",
        "                try:\n",
        "                    share_client.get_directory_client(FAIL_DIR).create_directory()\n",
        "                except Exception:\n",
        "                    pass\n",
        "                try:\n",
        "                    fail_dir.create_directory()\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "                fail_file = fail_dir.get_file_client(filename)\n",
        "                try:\n",
        "                    fail_file.delete_file()\n",
        "                except Exception:\n",
        "                    pass\n",
        "                fail_file.upload_file(image_bytes)\n",
        "\n",
        "                print(f\"    ‚è≠Ô∏è Skipped, moved {filename} to fail/{source_name}\")\n",
        "\n",
        "            # --- Update log with date, source, status ---\n",
        "            log_entry = f\"{today} | {source_name} | {filename} | {status}\"\n",
        "            processed_records.append(log_entry)\n",
        "            processed_lookup.add(filename)\n",
        "\n",
        "            log_content = \"\\n\".join(processed_records)\n",
        "            log_file_client = success_root.get_file_client(processed_log_name)\n",
        "            try:\n",
        "                log_file_client.delete_file()\n",
        "            except Exception:\n",
        "                pass\n",
        "            log_file_client.upload_file(log_content.encode(\"utf-8\"))\n",
        "\n",
        "            # Remove original from source after processing\n",
        "            try:\n",
        "                file_client.delete_file()\n",
        "                print(f\"    üóëÔ∏è Removed original {filename} from source/{source_name}\")\n",
        "            except Exception as e:\n",
        "                print(f\"    ‚ö†Ô∏è Could not delete original: {e}\")\n"
      ],
      "metadata": {
        "id": "X6_ypdVCUBwn"
      },
      "id": "X6_ypdVCUBwn",
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "cd99c710",
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "cd99c710",
        "outputId": "35fcbd53-379f-45fd-e06e-a10e2ac5c800"
      },
      "execution_count": null,
      "source": [
        "# --- Run the processing pipeline ---\n",
        "#process_files_in_root()\n",
        "process_all_sources()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Processing source folder: Eenadu\n",
            "  üñºÔ∏è Processing: babu Cabineat Meeting Comments ee21052025.jpeg\n",
            "    Category: News Article\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3296536776.py:73: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  today = datetime.utcnow().strftime(\"%Y-%m-%d\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ‚úÖ Saved babu Cabineat Meeting Comments ee21052025.jpeg and babu Cabineat Meeting Comments ee21052025.json to success/Eenadu\n",
            "    üóëÔ∏è Removed original babu Cabineat Meeting Comments ee21052025.jpeg from source/Eenadu\n",
            "üìÇ Processing source folder: sakshi\n"
          ]
        }
      ]
    }
  ]
}